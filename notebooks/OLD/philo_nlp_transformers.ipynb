{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_state = 42\n",
    "data_dir = '~/folders/Documents/study/NLP_PJ/philo/dataset'\n",
    "dl_folder = '~/folders/Documents/study/NLP_PJ/philo/dataset/dl/transformers'\n",
    "destination_folder = '~/folders/Documents/study/NLP_PJ/philo/results'\n",
    "filenames = [\n",
    "    'kant.txt', \n",
    "    'aristotle.txt', \n",
    "    'plato.txt', \n",
    "    'hume.txt',\n",
    "    'nietzsche.txt'\n",
    "    ]\n",
    "\n",
    "[os.path.join(data_dir, file) for file in filenames]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>stop_words_ratio</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>CONJ_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>PROPN_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>VERB_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19439</th>\n",
       "      <td>1</td>\n",
       "      <td>The parliament accordingly, in the ensuing yea...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>17</td>\n",
       "      <td>6.00</td>\n",
       "      <td>47.06</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>Now in experience our perceptions come togethe...</td>\n",
       "      <td>Kant</td>\n",
       "      <td>60</td>\n",
       "      <td>5.75</td>\n",
       "      <td>61.67</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>1</td>\n",
       "      <td>Knights and esquires, says the Dictum of Keni...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>42</td>\n",
       "      <td>4.64</td>\n",
       "      <td>54.76</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29084</th>\n",
       "      <td>1</td>\n",
       "      <td>It is come to this plain question, whether the...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>50</td>\n",
       "      <td>5.08</td>\n",
       "      <td>56.00</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87783</th>\n",
       "      <td>3</td>\n",
       "      <td>More truly implied, namely, that Practical Wis...</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>10</td>\n",
       "      <td>6.40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence     author  \\\n",
       "19439      1  The parliament accordingly, in the ensuing yea...       Hume   \n",
       "7039       0  Now in experience our perceptions come togethe...       Kant   \n",
       "18552      1   Knights and esquires, says the Dictum of Keni...       Hume   \n",
       "29084      1  It is come to this plain question, whether the...       Hume   \n",
       "87783      3  More truly implied, namely, that Practical Wis...  Aristotle   \n",
       "\n",
       "       word_count  mean_word_length  stop_words_ratio  stop_words_count  \\\n",
       "19439          17              6.00             47.06                 8   \n",
       "7039           60              5.75             61.67                37   \n",
       "18552          42              4.64             54.76                23   \n",
       "29084          50              5.08             56.00                28   \n",
       "87783          10              6.40             40.00                 4   \n",
       "\n",
       "       ADJ_count  ADV_count  ADP_count  ...  X_count  INTJ_count  CONJ_count  \\\n",
       "19439          2          1          1  ...        0           0           0   \n",
       "7039           2          7          9  ...        0           0           0   \n",
       "18552          2          1          4  ...        0           0           0   \n",
       "29084          3          2          7  ...        0           0           0   \n",
       "87783          0          3          1  ...        0           0           0   \n",
       "\n",
       "       CCONJ_count  SCONJ_count  PROPN_count  NOUN_count  PRON_count  \\\n",
       "19439            1            0            0           3           1   \n",
       "7039             2            3            0          15           1   \n",
       "18552            2            1            3          10           2   \n",
       "29084            2            2            1          12           2   \n",
       "87783            0            1            2           2           0   \n",
       "\n",
       "       PART_count  VERB_count  \n",
       "19439           0           3  \n",
       "7039            1           6  \n",
       "18552           1           5  \n",
       "29084           2           5  \n",
       "87783           0           1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'sentences.csv'\n",
    "data_csv = os.path.join(data_dir, csv_file)\n",
    "philo_df = pd.read_csv(data_csv).sample(frac = 1)\n",
    "philo_df = philo_df.iloc[:len(philo_df)//2]\n",
    "NUM_LABELS = len(philo_df.author.unique())\n",
    "philo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/pandas/core/frame.py:1485: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 'Hume', 0: 'Kant', 3: 'Aristotle', 2: 'Plato', 4: 'Nietzsche'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_aut = {}\n",
    "aut_label = philo_df[['author', 'label']].drop_duplicates().reset_index(drop=True).to_dict('record')\n",
    "for k in aut_label:\n",
    "    enc_aut[k['label']] = k['author']\n",
    "enc_aut    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label               0\n",
      "sentence            0\n",
      "author              0\n",
      "word_count          0\n",
      "mean_word_length    0\n",
      "stop_words_ratio    0\n",
      "stop_words_count    0\n",
      "ADJ_count           0\n",
      "ADV_count           0\n",
      "ADP_count           0\n",
      "AUX_count           0\n",
      "DET_count           0\n",
      "NUM_count           0\n",
      "X_count             0\n",
      "INTJ_count          0\n",
      "CONJ_count          0\n",
      "CCONJ_count         0\n",
      "SCONJ_count         0\n",
      "PROPN_count         0\n",
      "NOUN_count          0\n",
      "PRON_count          0\n",
      "PART_count          0\n",
      "VERB_count          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "author\n",
       "Aristotle    3\n",
       "Hume         1\n",
       "Kant         0\n",
       "Nietzsche    4\n",
       "Plato        2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = philo_df.isna()\n",
    "print(df_nan.sum())\n",
    "\n",
    "# print(philo_df.describe())\n",
    "\n",
    "philo_df['word_counter'] = philo_df['sentence'].apply(lambda x: x.count(' '))\n",
    "\n",
    "\n",
    "philo_df.groupby('author')['word_count'].mean().plot.bar()\n",
    "plt.show()\n",
    "philo_df.groupby('author')['label'].count().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "philo_df.groupby('author')['label'].size().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "philo_df.groupby('author')['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bettyld/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "first_n_words = 200\n",
    "\n",
    "def trim_string(x):\n",
    "    x = x.split(maxsplit=first_n_words)\n",
    "    x = ' '.join(x[:first_n_words])\n",
    "    return x\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "PATTERN_S = re.compile(\"\\'s\")\n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\")\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\")\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        # TODO What is doing spacy\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', ' ')\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    tokens = [w for w in text.split() if not w in STOPWORDS] # remove stopwors from text\n",
    "    # Remove short words (under 3 characters) from the tokens\n",
    "    long_words = []\n",
    "    for token in tokens:\n",
    "        if len(token) >= MIN_WORDS:\n",
    "            long_words.append(token)\n",
    "        else:\n",
    "            print('remove', token)\n",
    "    # Join the tokens back together\n",
    "    cleaned_text = (\" \".join(long_words)).strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19439</th>\n",
       "      <td>the parliament accordingly  in the ensuing yea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>now in experience our perceptions come togethe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>knights and esquires  says the dictum of keni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29084</th>\n",
       "      <td>it is come to this plain question  whether the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87783</th>\n",
       "      <td>more truly implied  namely  that practical wis...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11603</th>\n",
       "      <td>what are the negative conditions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53199</th>\n",
       "      <td>in the same manner the success of a partner re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76766</th>\n",
       "      <td>they both appear to me to be hunters</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94873</th>\n",
       "      <td>he who is a thorough teacher takes things seri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75010</th>\n",
       "      <td>one which you who live in a different atmosp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "19439  the parliament accordingly  in the ensuing yea...      1\n",
       "7039   now in experience our perceptions come togethe...      0\n",
       "18552   knights and esquires  says the dictum of keni...      1\n",
       "29084  it is come to this plain question  whether the...      1\n",
       "87783  more truly implied  namely  that practical wis...      3\n",
       "...                                                  ...    ...\n",
       "11603                  what are the negative conditions       0\n",
       "53199  in the same manner the success of a partner re...      1\n",
       "76766              they both appear to me to be hunters       2\n",
       "94873  he who is a thorough teacher takes things seri...      4\n",
       "75010    one which you who live in a different atmosp...      2\n",
       "\n",
       "[53567 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "# Processing the data\n",
    "# Drop empty text\n",
    "philo_df.drop(philo_df[philo_df.sentence.str.len()<5].index, inplace=True)\n",
    "\n",
    "# To try\n",
    "philo_df['sentence'] = philo_df['sentence'].apply(clean_text)\n",
    "# trim \n",
    "# philo_df['trim_sentence'] = philo_df['sentence'].apply(trim_string)\n",
    "\n",
    "# To try\n",
    "# stemmer = PorterStemmer()\n",
    "# philo_df[\"sentence\"] = philo_df['sentence'].str.split().apply(lambda x: ' '.join([stemmer.stem(w) for w in x]))\n",
    "\n",
    "mini_philo_df = philo_df[['sentence', 'label']]\n",
    "mini_philo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.80\n",
    "train_valid_ratio = 0.80\n",
    "df_train, df_test = train_test_split(mini_philo_df, train_size = train_test_ratio, random_state = ran_state)\n",
    "df_train, df_val = train_test_split(mini_philo_df, train_size = train_valid_ratio, random_state = ran_state)\n",
    "\n",
    "# Write preprocessed data\n",
    "df_train.to_csv(dl_folder + '/train.csv', index=False)\n",
    "df_val.to_csv(dl_folder + '/val.csv', index=False)\n",
    "df_test.to_csv(dl_folder + '/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "def generate_bigrams(seq):\n",
    "    \"\"\"\n",
    "    Add bigrams after 1-gram tokens.\n",
    "    >>> generate_bigrams(['This', 'film', 'is', 'terrible'])\n",
    "    >>> ['This', 'film', 'is', 'terrible', 'film is', 'is terrible', 'This film']\n",
    "    \"\"\"\n",
    "    n_grams = set(zip(*[seq[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        seq.append(' '.join(n_gram))\n",
    "    return seq\n",
    "\n",
    "# Create Fields\n",
    "# LABEL = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
    "# use_vocab=False, not be building our own vocabulary\n",
    "# tokenize=tokenizer.encode, using pre-trained BERT tokenizer and its corresponding word-to-index mapping\n",
    "LABEL = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
    "\n",
    "TEXT = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('sentence', TEXT), ('author', LABEL)]\n",
    "\n",
    "# Create TabularDataset\n",
    "train_data, valid_data, test_data = TabularDataset.splits(path=dl_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instances for training {text, label} {'sentence': [101, 1997, 2023, 2785, 2003, 1996, 4792, 1997, 7750, 2000, 2256, 6716, 1998, 1997, 8404, 2000, 2256, 2814, 9012, 11516, 1998, 1037, 2261, 2060, 20445, 18923, 2015, 102], 'author': '1'} <torchtext.data.example.Example object at 0x7f8d1c065310>\n"
     ]
    }
   ],
   "source": [
    "print('First instances for training {text, label}', vars(train_data[3]), train_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch instance according to their respective field \n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.sentence]:[torch.LongTensor of size 32x128]\n",
      "\t[.author]:[torch.LongTensor of size 32] tensor([[ 101, 2748, 2002,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 2079,  ...,    0,    0,    0],\n",
      "        [ 101, 5121, 2045,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  102,    0,  ...,    0,    0,    0],\n",
      "        [ 101,  102,    0,  ...,    0,    0,    0],\n",
      "        [ 101,  102,    0,  ...,    0,    0,    0]]) tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
      "        2, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[  101,  2008,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2812,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 10721,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1045,  2097,  ...,     0,     0,     0],\n",
      "        [  101,  2045,  2442,  ...,     0,     0,     0],\n",
      "        [  101,  2021,  2025,  ...,     0,     0,     0]]) tensor([2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/bettyld/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Iterators\n",
    "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.sentence),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.sentence),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iterator = Iterator(test_data, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)\n",
    "\n",
    "\n",
    "batch = next(iter(train_iterator))\n",
    "print('next batch instance according to their respective field', batch, batch.sentence, batch.author)\n",
    "for data in valid_iterator:\n",
    "    x, y = data.sentence, data.author\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "# Save and Load Functions\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    \"\"\"“bert-base-uncased” version of BERT, which is the smaller model trained on lower-cased English text (with 12-layer, 768-hidden, 12-heads, 110M parameters).\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name, num_labels=NUM_LABELS, \n",
    "                                                                     output_attentions=False,\n",
    "                                                                     output_hidden_states=False)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import tqdm \n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def fit(model, it, is_eval=False, optim=None, crit=None):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0; epoch_rec = 0; epoch_f1 = epoch_prec\n",
    "    if is_eval:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    for batch in tqdm.tqdm(it, total=len(it)):\n",
    "        if not is_eval:\n",
    "            optim.zero_grad()\n",
    "        text = batch.sentence\n",
    "        text = text.type(torch.LongTensor)\n",
    "        loss, preds = model(text, batch.author)\n",
    "#         try:\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "        acc = accuracy_score(batch.author.cpu().detach().numpy(), np.argmax(preds.cpu().detach().numpy(), axis=1))\n",
    "        if not is_eval:\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        else:\n",
    "            prec, recall, f1, _ = precision_recall_fscore_support(batch.author.cpu().detach().numpy(), np.argmax(preds.cpu().detach().numpy(), axis=1), average='weighted')\n",
    "            epoch_prec += prec\n",
    "            epoch_rec += recall\n",
    "            epoch_f1 += f1\n",
    "        epoch_loss += loss.item()\n",
    "        # epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(it), epoch_acc / len(it), epoch_prec / len(it), epoch_rec /len(it), epoch_f1 / len(it)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1340/1340 [15:38:07<00:00, 42.01s/it]      \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-5c413c4db5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-5c413c4db5a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, valid_loader, num_epochs, eval_every, file_path, best_valid_loss)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         train_loss, train_acc, _ = fit(model, train_iterator, is_eval=False,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                     optim=optimizer, crit=criterion)\n\u001b[1;32m     24\u001b[0m         valid_loss, valid_acc, val_prec, val_rec, val_f1 = fit(model, valid_iterator, is_eval=True,\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc, _ = fit(model, train_iterator, is_eval=False,\n",
    "                                    optim=optimizer, crit=criterion)\n",
    "        valid_loss, valid_acc, val_prec, val_rec, val_f1 = fit(model, valid_iterator, is_eval=True,\n",
    "                                         crit=criterion)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "       \n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Pre: {val_prec:.3f} |  Val. Rec: {val_rec*100:.2f}% | Val. F1: {val_f1*100:.2f}%')\n",
    "\n",
    "    # Last model\n",
    "    torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    print('Finished Training!')\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "model = BERT().to(device)\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tut2-model_trans.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 65/335 [09:24<39:05,  8.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-50fa2b3ea12c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tut2-model_trans.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test prec: {test_prec:.3f} | Test rec: {test_rec*100:.2f}% | Test f1: {test_f1*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-2d40a3783710>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, it, is_eval, optim, crit)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#         try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-d16a10829cd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_fea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_fea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1502\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         )\n\u001b[0;32m--> 971\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 )\n\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.load_state_dict(torch.load('tut2-model_trans.pt'))\n",
    "test_loss, test_acc, test_prec, test_rec, test_f1 = fit(model, test_iterator, crit=criterion, is_eval=True)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "print(f'Test prec: {test_prec:.3f} | Test rec: {test_rec*100:.2f}% | Test f1: {test_f1*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the difficulti on thi head must encreas when we consid that our judgment alter veri sensibl accord to the subject and that the same power and proxim will be deem possess in one case which is not esteem such in anoth \n",
      " Hume\n",
      "Prediction: Aristotle\n"
     ]
    }
   ],
   "source": [
    "# glove embed\n",
    "# from torchtext.vocab import GloVe\n",
    "# embedding_glove = GloVe(name='6B', dim=100)\n",
    "import random \n",
    "\n",
    "def generate_sentence(n):\n",
    "    sample = philo_df[['sentence', 'author']].iloc[n%len(philo_df)]\n",
    "    return sample.sentence, sample.author\n",
    "\n",
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    # split one sentence into list of words (smartly splitted by spacy)\n",
    "    tokenized = generate_bigrams([tok.text for tok in spacy_en.tokenizer(sentence)])\n",
    "    # Embedded with Glove\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    # Prepare input\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1).transpose(0,1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    out = model(tensor, length_tensor)\n",
    "    out = np.argmax(out.cpu().detach().numpy(), axis=1)[0]\n",
    "    author_label = LABEL.vocab.stoi[str(out)]\n",
    "    author_label = enc_aut[author_label]\n",
    "    return author_label\n",
    "sentence_ex, label_ex = generate_sentence(random.randint(0, len(philo_df)))\n",
    "print(sentence_ex, '\\n', label_ex)\n",
    "print('Prediction:', predict(model, sentence_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds =  [[0.48278892, 0.4991066,  0.5182273,  0.50137734, 0.5032032,  0.50438505],\n",
    "[0.48278892, 0.4991066,  0.5182273,  0.50137734, 0.5032032,  0.50438505]]\n",
    "np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    i shall therefor ventur to acknowledg that not...\n",
       "author                                                   Hume\n",
       "Name: 23620, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philo_df[['sentence', 'author']].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fdebe9f5160>>, {'<unk>': 0, '1': 1, '2': 2, '4': 3, '0': 4, '3': 5, 1: 0, 3: 0, '[4]': 0, '[1]': 0}) {1: 'Hume', 2: 'Plato', 4: 'Nietzsche', 3: 'Aristotle', 0: 'Kant'}\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi, enc_aut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
