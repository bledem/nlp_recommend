{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_state = 42\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = f'{current_dir}/dataset'\n",
    "dl_folder = f'{current_dir}/dataset/dl'\n",
    "destination_folder = f'{current_dir}/results'\n",
    "filenames = [\n",
    "    'kant.txt', \n",
    "    'aristotle.txt', \n",
    "    'plato.txt', \n",
    "    'hume.txt',\n",
    "    'nietzsche.txt'\n",
    "    ]\n",
    "\n",
    "[os.path.join(data_dir, file) for file in filenames]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>stop_words_ratio</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>...</th>\n",
       "      <th>X_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>CONJ_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>PROPN_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>VERB_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5873</td>\n",
       "      <td>0</td>\n",
       "      <td>For I first take the number 7, and, for the co...</td>\n",
       "      <td>Kant</td>\n",
       "      <td>68</td>\n",
       "      <td>3.84</td>\n",
       "      <td>60.29</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86561</td>\n",
       "      <td>3</td>\n",
       "      <td>Of Practical Wisdom exerted upon a community t...</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>39</td>\n",
       "      <td>5.23</td>\n",
       "      <td>61.54</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63769</td>\n",
       "      <td>2</td>\n",
       "      <td>: And we have admitted that a thing cannot be ...</td>\n",
       "      <td>Plato</td>\n",
       "      <td>19</td>\n",
       "      <td>4.47</td>\n",
       "      <td>68.42</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40021</td>\n",
       "      <td>1</td>\n",
       "      <td>Cospatric also, in despair of success, made h...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>36</td>\n",
       "      <td>4.86</td>\n",
       "      <td>58.33</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95585</td>\n",
       "      <td>4</td>\n",
       "      <td>From German body, this self-lacerating?</td>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                           sentence     author  \\\n",
       "0   5873      0  For I first take the number 7, and, for the co...       Kant   \n",
       "1  86561      3  Of Practical Wisdom exerted upon a community t...  Aristotle   \n",
       "2  63769      2  : And we have admitted that a thing cannot be ...      Plato   \n",
       "3  40021      1   Cospatric also, in despair of success, made h...       Hume   \n",
       "4  95585      4            From German body, this self-lacerating?  Nietzsche   \n",
       "\n",
       "   word_count  mean_word_length  stop_words_ratio  stop_words_count  \\\n",
       "0          68              3.84             60.29                41   \n",
       "1          39              5.23             61.54                24   \n",
       "2          19              4.47             68.42                13   \n",
       "3          36              4.86             58.33                21   \n",
       "4           5              7.00             40.00                 2   \n",
       "\n",
       "   ADJ_count  ADV_count  ...  X_count  INTJ_count  CONJ_count  CCONJ_count  \\\n",
       "0          0          5  ...        0           0           0            2   \n",
       "1          2          1  ...        0           0           0            2   \n",
       "2          0          0  ...        0           0           0            2   \n",
       "3          0          2  ...        0           0           0            2   \n",
       "4          1          0  ...        0           0           0            0   \n",
       "\n",
       "   SCONJ_count  PROPN_count  NOUN_count  PRON_count  PART_count  VERB_count  \n",
       "0            1            0          18           4           1           6  \n",
       "1            1            6           5           1           0           4  \n",
       "2            1            0           3           2           1           3  \n",
       "3            1            2          10           0           0           4  \n",
       "4            0            0           2           0           0           1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'sentences.csv'\n",
    "data_csv = os.path.join(data_dir, csv_file)\n",
    "philo_df = pd.read_csv(data_csv).sample(frac = 1)\n",
    "# philo_df = philo_df.loc[philo_df.author=='Nietzsche']\n",
    "philo_all_df = philo_df.copy()\n",
    "philo_df = philo_df.iloc[:len(philo_df)//2]\n",
    "philo_df = philo_df.reset_index()\n",
    "philo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEtCAYAAAAIrhf1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXMklEQVR4nO3dfbRddX3n8fcHokJRKEpEhoABSaWASiUyoE4Hi1OoiKADTqgPUNGMFkdbna6B1o7tdFjqcilLXAOaFuShVkQqFbU+MKhQFYGgyJNSUkFJyZAIiCkd0OB3/ti/a04uN8m5Nzd3n8x5v9Y665zzPXuffO9ZN/dz9m/v/dupKiRJ2q7vBiRJo8FAkCQBBoIkqTEQJEmAgSBJagwESRIA8/puYKZ22223WrhwYd9tSNI25cYbb/xxVc2f6rVtNhAWLlzI8uXL+25DkrYpSX64sdccMpIkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpGabPTFNs2vh6Z/vuwXufu8xfbcgjTW3ECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBAwRCEn2SvLVJN9LcluSt7f6U5NcmeTOdr/rwDpnJFmR5I4kRw3UD0lyS3vt7CRp9Scl+WSrX5dk4Vb4WSVJmzDMFsI64J1V9evAYcBpSQ4ATgeuqqpFwFXtOe21JcCBwNHAOUm2b+91LrAUWNRuR7f6qcCDVbUfcBbwvln42SRJ07DZQKiqVVX17fZ4LfA9YE/gOODCttiFwPHt8XHAJVX1aFXdBawADk2yB7BzVV1bVQVcNGmdife6DDhyYutBkjQ3prUPoQ3l/AZwHbB7Va2CLjSAp7fF9gTuGVhtZavt2R5Prm+wTlWtAx4Cnjad3iRJW2boQEjyZOBvgT+oqp9uatEparWJ+qbWmdzD0iTLkyxfs2bN5lqWJE3DUIGQ5Al0YfDxqvp0K9/XhoFo96tbfSWw18DqC4B7W33BFPUN1kkyD9gFeGByH1W1rKoWV9Xi+fPnD9O6JGlIwxxlFOA84HtV9cGBl64ATm6PTwY+M1Bf0o4c2odu5/H1bVhpbZLD2nu+ftI6E+91AvCVtp9BkjRH5g2xzIuA1wG3JLmp1f4YeC9waZJTgR8BJwJU1W1JLgVupztC6bSqeqyt9xbgAmBH4AvtBl3gXJxkBd2WwZIt+7EkSdO12UCoqq8z9Rg/wJEbWedM4Mwp6suBg6aoP0ILFElSPzxTWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkScAQgZDk/CSrk9w6UPuzJP+c5KZ2e9nAa2ckWZHkjiRHDdQPSXJLe+3sJGn1JyX5ZKtfl2ThLP+MkqQhDLOFcAFw9BT1s6rq4Hb7e4AkBwBLgAPbOuck2b4tfy6wFFjUbhPveSrwYFXtB5wFvG+GP4skaQtsNhCq6hrggSHf7zjgkqp6tKruAlYAhybZA9i5qq6tqgIuAo4fWOfC9vgy4MiJrQdJ0tzZkn0Ib01ycxtS2rXV9gTuGVhmZavt2R5Prm+wTlWtAx4CnjbVP5hkaZLlSZavWbNmC1qXJE0200A4F3gWcDCwCvhAq0/1zb42Ud/UOo8vVi2rqsVVtXj+/PnTaliStGkzCoSquq+qHquqXwB/CRzaXloJ7DWw6ALg3lZfMEV9g3WSzAN2YfghKknSLJlRILR9AhNeCUwcgXQFsKQdObQP3c7j66tqFbA2yWFt/8Drgc8MrHNye3wC8JW2n0GSNIfmbW6BJJ8AjgB2S7ISeDdwRJKD6YZ27gb+M0BV3ZbkUuB2YB1wWlU91t7qLXRHLO0IfKHdAM4DLk6ygm7LYMks/FySpGnabCBU1UlTlM/bxPJnAmdOUV8OHDRF/RHgxM31IUnaujxTWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSp2WwgJDk/yeoktw7UnprkyiR3tvtdB147I8mKJHckOWqgfkiSW9prZydJqz8pySdb/bokC2f5Z5QkDWGYLYQLgKMn1U4HrqqqRcBV7TlJDgCWAAe2dc5Jsn1b51xgKbCo3Sbe81TgwaraDzgLeN9MfxhJ0sxtNhCq6hrggUnl44AL2+MLgeMH6pdU1aNVdRewAjg0yR7AzlV1bVUVcNGkdSbe6zLgyImtB0nS3JnpPoTdq2oVQLt/eqvvCdwzsNzKVtuzPZ5c32CdqloHPAQ8bap/NMnSJMuTLF+zZs0MW5ckTWW2dypP9c2+NlHf1DqPL1Ytq6rFVbV4/vz5M2xRkjSVeTNc774ke1TVqjYctLrVVwJ7DSy3ALi31RdMUR9cZ2WSecAuPH6ISpJ6tfD0z/fdAne/95it+v4z3UK4Aji5PT4Z+MxAfUk7cmgfup3H17dhpbVJDmv7B14/aZ2J9zoB+ErbzyBJmkOb3UJI8gngCGC3JCuBdwPvBS5NcirwI+BEgKq6LcmlwO3AOuC0qnqsvdVb6I5Y2hH4QrsBnAdcnGQF3ZbBkln5ySRJ07LZQKiqkzby0pEbWf5M4Mwp6suBg6aoP0ILFElSfzxTWZIEzHynsqQxMA47UrWeWwiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgCY13cD0qhZePrn+26Bu997TN8taAy5hSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUrNFgZDk7iS3JLkpyfJWe2qSK5Pc2e53HVj+jCQrktyR5KiB+iHtfVYkOTtJtqQvSdL0zcYWwkuq6uCqWtyenw5cVVWLgKvac5IcACwBDgSOBs5Jsn1b51xgKbCo3Y6ehb4kSdOwNYaMjgMubI8vBI4fqF9SVY9W1V3ACuDQJHsAO1fVtVVVwEUD60iS5siWznZawJeTFPDRqloG7F5VqwCqalWSp7dl9wS+NbDuylb7eXs8ub7VOaulJK23pYHwoqq6t/3RvzLJ9zex7FT7BWoT9ce/QbKUbmiJvffee7q9SpI2YYuGjKrq3na/GrgcOBS4rw0D0e5Xt8VXAnsNrL4AuLfVF0xRn+rfW1ZVi6tq8fz587ekdUnSJDMOhCQ7JXnKxGPgt4FbgSuAk9tiJwOfaY+vAJYkeVKSfeh2Hl/fhpfWJjmsHV30+oF1JElzZEuGjHYHLm9HiM4D/qaqvpjkBuDSJKcCPwJOBKiq25JcCtwOrANOq6rH2nu9BbgA2BH4QrtJkubQjAOhqn4APG+K+v3AkRtZ50zgzCnqy4GDZtqLJGnLeaayJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSgBEKhCRHJ7kjyYokp/fdjySNm5EIhCTbA/8L+B3gAOCkJAf025UkjZeRCATgUGBFVf2gqn4GXAIc13NPkjRWUlV990CSE4Cjq+qN7fnrgH9bVW+dtNxSYGl7+mzgjjltdGq7AT/uu4kR4WfR8XNYz89ivVH5LJ5ZVfOnemHeXHeyEZmi9rikqqplwLKt387wkiyvqsV99zEK/Cw6fg7r+Vmsty18FqMyZLQS2Gvg+QLg3p56kaSxNCqBcAOwKMk+SZ4ILAGu6LknSRorIzFkVFXrkrwV+BKwPXB+Vd3Wc1vDGqkhrJ75WXT8HNbzs1hv5D+LkdipLEnq36gMGUmSemYgSJIAA0GS1BgImhVJduq7hz4lefswtXGRZMckz+67D02PgTADSZ6Z5KXt8Y5JntJ3T31J8sIktwPfa8+fl+Scntvqw8lT1E6Z6yZGQZJjgZuAL7bnBycZ28PIk+ye5OXt9vS++9kUA2GakrwJuAz4aCstAP6ut4b6dxZwFHA/QFV9F/jNXjuaQ0lOSvJZYJ8kVwzcvkr7TMbQn9HNT/YTgKq6CVjYWzc9SvJq4HrgRODVwHVtqp6RNBLnIWxjTqP7Zb8OoKruHPXU39qq6p5kg9lHHuurlx58E1hFN0/NBwbqa4Gbe+mof+uq6qFJvxPj6k+AF1TVaoAk84H/TfelcuQYCNP3aFX9bOKXPck8pph3aYzck+SFQLWzzN9GGz4aB1X1Q+CHwOF99zJCbk3yu8D2SRbR/U58s+ee+rLdRBg09zPCIzMj29gIuzrJHwM7JvkPwKeAz/bcU5/eTLfVtCfdnFQHt+djJcmrktyZ5KEkP02yNslP++6rJ/8FOBB4FPgE8FPgD/psqEdfTPKlJKckOQX4PPCFnnvaKM9UnqYk2wGnAr9NN0vrl4C/Kj/IsZZkBXBsVY3N1pGGk+RVwIvp/l5cU1WX99zSRhkI2iJJ9qH7RriQgSHIqnpFXz31Ick3qupFffcxCpL8GvBfefzvxG/11VNfkryvqv7b5mqjwkAYUpJb2MS+gqp67hy2MzKSfBc4D7gF+MVEvaqu7q2pHiT5EPAMuiPOHp2oV9Wn++qpL+134iPAjQwcYFBVN/bWVE+SfLuqnj+pdvOo/r1wp/LwXt53AyPqkao6u+8mRsDOwL/SDSVOKGDsAoHuKKNz+26iT0neAvw+sG+SwaPNngJ8o5+uNs8thGna1jYBt7Z2NMki4Mts+M342701pV4keWp7+DZgNXA5G/5OPNBHX31IsguwK/Ae4PSBl9aO8udgIEzTtrYJuLUleQ/wOuCfWD9kVOM2XpxkB7qDDQ4EdpioV9UbemtqjiW5i26raMpL4lbVvnPc0sho5yoN/l78qMd2NsohoyFtq5uAc+CVwL5V9bO+G+nZxcD36c7a/h/Aaxij8zEAqmqfvnsYNW0ajw8C/4Zuq+mZdL8XB/bZ18Z4HsLw/gY4lu7SnscO3A6pqtf22VjPvgv8at9NjID9qupPgYer6kLgGOA5PffUiySnJfnVgee7Jvn9Hlvq0/8EDgP+sQXmkYzwF0gDYUhV9VBV3V1VJ9H9AZwIhL16bax/uwPfbyff/HIun76b6sHP2/1PkhwE7MKYzt8DvKmqfjLxpKoeBN7UXzu9+nlV3Q9sl2S7qvoq3cmbI8kho2lK8jZgKeuPHvnrJMuq6sM9ttWnd/fdwIhYlmRX4F10W5FPBv6035Z6s12STJysmWR74Ik999SXnyR5MnAN8PEkq4F1Pfe0Ue5Unqa2/+Dwqnq4Pd8JuHZcdyqPuyQLqmrlRl47tqrGblqTJO+n2zr6CN1O5jcD91TVO/vsqw/t78MjdDvaX0O35fjxttUwcgyEaWonqL2gqh5pz3cAbqiqcR0vXsv6E/aeCDyBbhx95/66mjtJ7gCOqqq7J9V/D3hXVT2rl8Z61KZ3WQq8lO4P4ZfppncZp1lwt0kOGU3fx+jmNJ+Yj+R44Pz+2ulXVW1wcaAkx9NNDz4u/hC4MsnLqupOgCRnAL8L/PteO+tJVf2CbuvgI+3chAXjFgYDX5QmDsGd+NIUukNwR/ILk1sIM5Dk+Ww4WdV3em5ppCT5VlUd1ncfcyXJkXQXTDoeeCPwAuDlbWfq2EnyNeAVdF84bwLWAFdX1Tt6bEtDcAthmpJcXFWvA749RW3stJkcJ2wHLGbMrg9RVVe1qY2/Rjfv/5ETQ4pjapeq+mmSNwIfq6p3Tzp35/97bSj5zcB+dBdKOr+qRnZn8gQDYfo2OKGkHUFxSE+9jIJjBx6vA+4Gjuunlbk3aWjgSXTHma9OdwWlkR0a2MrmJdmD7pKRf9J3Mz25kO5Q5H8AXkb3d+PtvXY0BANhSG1ceOLCOBMXPgnwM2BZb431rKp+r+8e+jR5H4qA7kztLwFfr6obkuwL3NlzT3PtgIkDTZKcR3dd5ZHnPoRpSvKeqjqj7z76luTDbHo68LfNYTsaIUn2qqp7JtWeUVX/p6+e5trkOc+mmgNtFLmFMH2fS7JTVT2c5LXA84EPtWvrjpPlA4//HE9Q03p3JfkU8Iaq+r+t9vd0/1fGxfMmjSRMjCyM9FCiWwjT1HaOPQ94Lt2EZucBr6qqsTzEECDJd6rqN/ruQ6MhyXeAv6Sb/fXVVfVP/o5sG5zLaPrWtVPyj6PbMvgQ3Yyn48xvFRpUVXUO3XURPttm/PR3ZBvgkNH0rW07mF8L/GY7yugJPfckjZIAVNU32jkanwT277clDcMho2lK8gy6s1BvqKp/SLI3cERVXdRza3Nq0pQVv0J3+UgY8TFSbX1JXlhV3xx4Pg94YVVd02NbGoKBIGlWbeSqgjdW1Tifr7NNcMhoSEm+XlUvnvTNGPxGLAGQZH+6E7B2mXQG+84MXD5So8tAGFJVvbjdj/sOZGljng28nPUXkJqwlvG9QM42xSGjaWjT+t5cVQf13Ys0qpIcXlXX9t2Hps/DTqehTev73bYjWdLU7k9yVZJbAZI8N8m7+m5Km+cWwjQl+Qrd9MbXAw+3clXV2EzoJm1KkquBPwI+OnEyWpJb3bIefe5DmL4/H3gcuusinNRTL9Io+pWqur6b8PWXRn7qZzlkNG1VdTXwEHAMcAHddMcf6bMnacT8OMmzaEfjJTkBWNVvSxqGWwhDSvJrwBK6rYH76c6+TFW9pNfGpNFzGt2U8Psn+WfgLroz+zXi3IcwpCS/oLvYxalVtaLVflBV+/bbmTSakuwEbFdVa/vuRcNxC2F4/5FuC+GrSb4IXML6C2hLYy/Ja6vqr5O8Y1IdgKr6YC+NaWgGwpCq6nLg8vat53jgD4Hdk5wLXF5VX+6zP2kE7NTuPXlzG+WQ0RZI8lTgROA/VdVv9d2PJG0JA0HSrEjy3zfxclXVX8xZM5oRA0HSrEjyzinKO9FdOe1pVfXkOW5J02QgSJp1SZ4CvJ0uDC4FPlBVq/vtSpvjTmVJs6btV3sH8BrgQuD5VfVgv11pWAaCpFmR5P3Aq+hOSntOVf1Lzy1pmhwykjQr2smbj9LNW+RFpLZBBoIkCXByO0lSYyBIkgADQZoVSY5PcsDA868lWdxnT9J0GQjS7DgeOGBzCw0jiUf/qRcGgrQRSf4uyY1JbkuytNX+ZeD1E5JckOSFwCuA9ye5qV0cBuDEJNcn+cck/66ts0OSjyW5Jcl3kryk1U9J8qkknwWcKFG98JuItHFvqKoHkuwI3JDkb6daqKq+meQK4HNVdRn8csrneVV1aJKXAe8GXkp38Riq6jlJ9ge+3C6+BHA48NyqemDr/ljS1AwEaePeluSV7fFewKJprv/pdn8jsLA9fjHwYYCq+n6SHwITgXClYaA+GQjSFJIcQfeN/vCq+tckXwN2YMMTrnbYzNs82u4fY/3/tU1dVOnhaTcqzSL3IUhT2wV4sIXB/sBhrX5fkl9Psh3wyoHl1zLchWGuoZvnZ+I63XsDd8xe29LMGQjS1L4IzEtyM/AXwLda/XTgc8BXgFUDy18C/FHbUfwsNu4cYPsktwCfBE6pqkc3sbw0Z5y6QpIEuIUgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEkA/D/aoaujEOyeXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "author\n",
       "Aristotle    3\n",
       "Hume         1\n",
       "Kant         0\n",
       "Nietzsche    4\n",
       "Plato        2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = philo_df.isna()\n",
    "# print(df_nan.sum())\n",
    "\n",
    "# print(philo_df.describe())\n",
    "\n",
    "philo_df['word_counter'] = philo_df['sentence'].apply(lambda x: x.count(' '))\n",
    "\n",
    "\n",
    "philo_df.groupby('author')['word_count'].mean().plot.bar()\n",
    "plt.show()\n",
    "philo_df.groupby('author')['label'].count().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "philo_df.groupby('author')['label'].size().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "philo_df.groupby('author')['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/bettyld/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "first_n_words = 200\n",
    "\n",
    "def trim_string(x):\n",
    "    x = x.split(maxsplit=first_n_words)\n",
    "    x = ' '.join(x[:first_n_words])\n",
    "    return x\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "PATTERN_S = re.compile(\"\\'s\")\n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\")\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\")\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 2\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        # TODO What is doing spacy\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', ' ')\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    tokens = [w for w in text.split() if not w in STOPWORDS] # remove stopwors from text\n",
    "    # Remove short words (under 3 characters) from the tokens\n",
    "    long_words = []\n",
    "    for token in tokens:\n",
    "        if len(token) >= MIN_WORDS:\n",
    "            long_words.append(token)\n",
    "    # Join the tokens back together\n",
    "    cleaned_text = (\" \".join(long_words)).strip()\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "# Processing the data\n",
    "# Drop empty text\n",
    "philo_df.drop(philo_df[philo_df.sentence.str.len()<3].index, inplace=True)\n",
    "\n",
    "# To try\n",
    "philo_df['clean_sentence'] = philo_df['sentence'].apply(clean_text)\n",
    "philo_all_df['clean_sentence'] = philo_all_df['sentence'].apply(clean_text)\n",
    "# trim \n",
    "# philo_df['trim_sentence'] = philo_df['sentence'].apply(trim_string)\n",
    "\n",
    "philo_df['clean_sentence'] = philo_df['clean_sentence'].apply(lambda x: x.lower())\n",
    "philo_df['sentence'] = philo_df['clean_sentence'].apply(lambda x: re.sub('[^A-Za-z0-9]+', ' ', x))\n",
    "\n",
    "# # To try\n",
    "# stemmer = PorterStemmer()\n",
    "# philo_df[\"sentence\"] = philo_df['stem_sentence'].str.split().apply(lambda x: ' '.join([stemmer.stem(w.lower()) for w in x]))\n",
    "\n",
    "mini_philo_df = philo_df[['sentence', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>stop_words_ratio</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>...</th>\n",
       "      <th>CONJ_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>PROPN_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>VERB_count</th>\n",
       "      <th>word_counter</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5873</td>\n",
       "      <td>0</td>\n",
       "      <td>first take number conception calling aid finge...</td>\n",
       "      <td>Kant</td>\n",
       "      <td>68</td>\n",
       "      <td>3.84</td>\n",
       "      <td>60.29</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>first take number conception calling aid finge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86561</td>\n",
       "      <td>3</td>\n",
       "      <td>practical wisdom erted upon community would ca...</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>39</td>\n",
       "      <td>5.23</td>\n",
       "      <td>61.54</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>practical wisdom erted upon community would ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63769</td>\n",
       "      <td>2</td>\n",
       "      <td>admitted thing cannot taught neither teachers ...</td>\n",
       "      <td>Plato</td>\n",
       "      <td>19</td>\n",
       "      <td>4.47</td>\n",
       "      <td>68.42</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>admitted thing cannot taught neither teachers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40021</td>\n",
       "      <td>1</td>\n",
       "      <td>cospatric also despair success made peace king...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>36</td>\n",
       "      <td>4.86</td>\n",
       "      <td>58.33</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>cospatric also despair success made peace king...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95585</td>\n",
       "      <td>4</td>\n",
       "      <td>german body self lacerating</td>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>german body self lacerating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53562</th>\n",
       "      <td>80689</td>\n",
       "      <td>3</td>\n",
       "      <td>sicily countries abundant supply goats milk mi...</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>41</td>\n",
       "      <td>4.46</td>\n",
       "      <td>60.98</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>sicily countries abundant supply goats milk mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53563</th>\n",
       "      <td>44959</td>\n",
       "      <td>1</td>\n",
       "      <td>besides taking oaths allegiance supremacy rece...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>28</td>\n",
       "      <td>5.64</td>\n",
       "      <td>53.57</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>besides taking oaths allegiance supremacy rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53564</th>\n",
       "      <td>21344</td>\n",
       "      <td>1</td>\n",
       "      <td>bishop winchester care kings person education ...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>64</td>\n",
       "      <td>5.00</td>\n",
       "      <td>56.25</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>bishop winchester care kings person education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53565</th>\n",
       "      <td>42216</td>\n",
       "      <td>1</td>\n",
       "      <td>king never content stated rents levied heavy t...</td>\n",
       "      <td>Hume</td>\n",
       "      <td>28</td>\n",
       "      <td>4.82</td>\n",
       "      <td>53.57</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>king never content stated rents levied heavy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53566</th>\n",
       "      <td>17493</td>\n",
       "      <td>1</td>\n",
       "      <td>father paul lib father paul lib</td>\n",
       "      <td>Hume</td>\n",
       "      <td>7</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>father paul lib father paul lib</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53567 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  label                                           sentence  \\\n",
       "0       5873      0  first take number conception calling aid finge...   \n",
       "1      86561      3  practical wisdom erted upon community would ca...   \n",
       "2      63769      2  admitted thing cannot taught neither teachers ...   \n",
       "3      40021      1  cospatric also despair success made peace king...   \n",
       "4      95585      4                        german body self lacerating   \n",
       "...      ...    ...                                                ...   \n",
       "53562  80689      3  sicily countries abundant supply goats milk mi...   \n",
       "53563  44959      1  besides taking oaths allegiance supremacy rece...   \n",
       "53564  21344      1  bishop winchester care kings person education ...   \n",
       "53565  42216      1  king never content stated rents levied heavy t...   \n",
       "53566  17493      1                    father paul lib father paul lib   \n",
       "\n",
       "          author  word_count  mean_word_length  stop_words_ratio  \\\n",
       "0           Kant          68              3.84             60.29   \n",
       "1      Aristotle          39              5.23             61.54   \n",
       "2          Plato          19              4.47             68.42   \n",
       "3           Hume          36              4.86             58.33   \n",
       "4      Nietzsche           5              7.00             40.00   \n",
       "...          ...         ...               ...               ...   \n",
       "53562  Aristotle          41              4.46             60.98   \n",
       "53563       Hume          28              5.64             53.57   \n",
       "53564       Hume          64              5.00             56.25   \n",
       "53565       Hume          28              4.82             53.57   \n",
       "53566       Hume           7              4.29              0.00   \n",
       "\n",
       "       stop_words_count  ADJ_count  ADV_count  ...  CONJ_count  CCONJ_count  \\\n",
       "0                    41          0          5  ...           0            2   \n",
       "1                    24          2          1  ...           0            2   \n",
       "2                    13          0          0  ...           0            2   \n",
       "3                    21          0          2  ...           0            2   \n",
       "4                     2          1          0  ...           0            0   \n",
       "...                 ...        ...        ...  ...         ...          ...   \n",
       "53562                25          3          4  ...           0            3   \n",
       "53563                15          0          0  ...           0            2   \n",
       "53564                36          6          0  ...           0            7   \n",
       "53565                15          2          1  ...           0            2   \n",
       "53566                 0          0          0  ...           0            1   \n",
       "\n",
       "       SCONJ_count  PROPN_count  NOUN_count  PRON_count  PART_count  \\\n",
       "0                1            0          18           4           1   \n",
       "1                1            6           5           1           0   \n",
       "2                1            0           3           2           1   \n",
       "3                1            2          10           0           0   \n",
       "4                0            0           2           0           0   \n",
       "...            ...          ...         ...         ...         ...   \n",
       "53562            2            1           9           6           1   \n",
       "53563            1            0           8           1           1   \n",
       "53564            1            1          18           4           1   \n",
       "53565            0            0           8           1           0   \n",
       "53566            0            6           0           0           0   \n",
       "\n",
       "       VERB_count  word_counter  \\\n",
       "0               6            67   \n",
       "1               4            38   \n",
       "2               3            18   \n",
       "3               4            36   \n",
       "4               1             4   \n",
       "...           ...           ...   \n",
       "53562           3            40   \n",
       "53563           5            27   \n",
       "53564           3            64   \n",
       "53565           3            27   \n",
       "53566           0             6   \n",
       "\n",
       "                                          clean_sentence  \n",
       "0      first take number conception calling aid finge...  \n",
       "1      practical wisdom erted upon community would ca...  \n",
       "2      admitted thing cannot taught neither teachers ...  \n",
       "3      cospatric also despair success made peace king...  \n",
       "4                            german body self lacerating  \n",
       "...                                                  ...  \n",
       "53562  sicily countries abundant supply goats milk mi...  \n",
       "53563  besides taking oaths allegiance supremacy rece...  \n",
       "53564  bishop winchester care kings person education ...  \n",
       "53565  king never content stated rents levied heavy t...  \n",
       "53566                    father paul lib father paul lib  \n",
       "\n",
       "[53567 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "philo_df['spacy_sentence'] = philo_df['sentence'].apply(lambda x: nlp(x.lower())) # calling nlp on a string and spaCy tokenizes the text and creates a document object\n",
    "philo_df['spacy_sentence_token'] = philo_df['sentence'].apply(lambda x: nlp(x.lower()).text.split()) # calling nlp on a string and spaCy tokenizes the text and creates a document object\n",
    "\n",
    "# philo_all_df['spacy_sentence'] = philo_all_df['sentence'].apply(lambda x: nlp(x.lower())) # calling nlp on a string and spaCy tokenizes the text and creates a document object\n",
    "philo_df['spacy_vec'] = philo_df['spacy_sentence'].apply(lambda x: np.array(x.vector))\n",
    "philo_df['spacy_vec'] = philo_df['spacy_vec'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "\n",
    "# Version 1\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Using TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3)) #one gram to three gram\n",
    "tfidf_mat = vectorizer.fit_transform(philo_df['sentence'])\n",
    "# Compute cosine similarity\n",
    "cosine_sim_mat = cosine_similarity(tfidf_mat, tfidf_mat)\n",
    "# cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 tfidf recommandation matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                           sentence  \\\n",
      "52923                                                                      conceal cold hot weather   \n",
      "22104                                                                          also eat sweet fruit   \n",
      "8007   soup meal meat boiled shreds vegetables cooked fat flour degeneration pastries paper weights   \n",
      "\n",
      "          author  \n",
      "52923  Aristotle  \n",
      "22104  Aristotle  \n",
      "8007   Nietzsche  \n"
     ]
    }
   ],
   "source": [
    "# print(tfidf_mat.shape) \n",
    "# print(cosine_sim_mat.shape)\n",
    "\n",
    "def get_recommendations_v1(sentence, series):\n",
    "    tokens = [str(tok) for tok in nlp(sentence)]\n",
    "    # using tfidf\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # using spacy\n",
    "#     print('computing similarity')\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    best_sim_each_token = np.argmax(mat, axis=1)\n",
    "    index = np.argsort(best_sim_each_token)[::-1] #take the five highest norm \n",
    "#     print('norms, indices', best_sim_each_token, index)\n",
    "    null_index = best_sim_each_token != 0\n",
    "    null_index = null_index[index]\n",
    "    index = index[null_index==True]\n",
    "    best_index = best_sim_each_token[index][:3]\n",
    "#     print('best_index', best_index)\n",
    "    print(philo_df[['sentence', 'author']].iloc[best_index])\n",
    "    return best_index\n",
    "\n",
    "\n",
    "mat = get_recommendations_v1('Can I eat a hot soup tonight?', philo_df['sentence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 spacy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing similarity\n",
      "(8, 300) (2000, 300)\n",
      "norms, indices [ 807 1420  648 1163 1735 1776  773  574] [5 4 1 3 0 6 2 7]\n",
      "best_index [1776 1735 1420]\n",
      "                                                                                                                                                                                                                                                                                             sentence  \\\n",
      "1776  adeps and fat differ from each other for fat is always brittle and coagulates upon cooling but adeps is liquid and does not coagulate and broths made from animals with adeps do not thicken as from the horse and hog but that made from animals with fat thickens as from the sheep and goat    \n",
      "1735                                                                                                                                                                                                                     when the young are born the dam licks them in order to warm and mature them    \n",
      "1420                                                                                                                                                                                                                                                                 well i said i submit to my fate    \n",
      "\n",
      "         author  \n",
      "1776  Aristotle  \n",
      "1735  Aristotle  \n",
      "1420      Plato  \n"
     ]
    }
   ],
   "source": [
    "def get_recommendations_v2(sentence, series):\n",
    "    vec = np.array([tok.vector for tok in nlp(sentence)])\n",
    "    print('computing similarity')\n",
    "    data_vec = np.array([np.array(elt) for elt in philo_df['spacy_vec'].values])\n",
    "    print(vec.shape, data_vec.shape)\n",
    "    mat = cosine_similarity(vec, data_vec)\n",
    "    best_sim_each_token = np.argmax(mat, axis=1)\n",
    "    index = np.argsort(best_sim_each_token)[::-1] #take the five highest norm \n",
    "    print('norms, indices', best_sim_each_token, index)\n",
    "    null_index = best_sim_each_token != 0\n",
    "    null_index = null_index[index]\n",
    "    index = index[null_index==True]\n",
    "    best_index = best_sim_each_token[index][:3]\n",
    "    print('best_index', best_index)\n",
    "    print(philo_df[['sentence', 'author']].iloc[best_index])\n",
    "    return best_index\n",
    "\n",
    "\n",
    "mat = get_recommendations_v2('Can I eat a hot soup tonight?', philo_df['sentence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bettyld/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "# Version #3 with word2vec gensim\n",
    "# missing keys (common words)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "import gensim.downloader as api\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "# 'glove-wiki-gigaword-300'\n",
    "\n",
    "# glove_vectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "glove_vectors = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.KeyedVectors object at 0x7f95bee00520>\n",
      "<gensim.models.keyedvectors.KeyedVectors object at 0x7f95bee00520>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=philo_df.spacy_sentence.values, vector_size=300, window=5, min_count = 1, workers = 2)\n",
    "word2vec_model.build_vocab(philo_df.sentence.values)\n",
    "print(word2vec_model.wv)\n",
    "# word2vec_model.intersect_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', lockf=0.0,binary=True)\n",
    "word2vec_model.train(philo_df.sentence.values, total_examples=2, epochs = 2)\n",
    "print(word2vec_model.wv)\n",
    "word2vec_model.save('my_gensim_word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[observe dionysius halicarnassus says regard ancient walls rome tent city appear greater athens must mean acropolis high town\n",
      " even earl derby rebelled pardoned restored fortune obliged pay seven years rent second time restored\n",
      " articles inquiry concerning conduct sheriffs henry promulgated 1170 show great power well licentiousness officers\n",
      " ... ioms properly relate quantities\n",
      " determination pure intuition obtain priori cognitions objects mathematics regards form phenomena whether ist things must intuited form thereby established\n",
      " thus still find whatever causes fluctuation mi ture passions degree uneasiness always produces fear least passion like scarcely distinguished]\n",
      "{' ': 0, 'e': 1, 'n': 2, 'i': 3, 's': 4, 't': 5, 'r': 6, 'a': 7, 'o': 8, 'l': 9, 'd': 10, 'c': 11, 'u': 12, 'p': 13, 'm': 14, 'h': 15, 'g': 16, 'y': 17, 'f': 18, 'v': 19, 'b': 20, 'w': 21, 'k': 22, 'j': 23, 'q': 24, 'z': 25, '1': 26, '0': 27, '2': 28, '3': 29, '6': 30, '5': 31, '4': 32, '7': 33, '9': 34, '8': 35}\n"
     ]
    }
   ],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "# philo_df['gensim_vec'] = philo_df['spacy_sentence'].apply(lambda x: [word2vec_model.wv[elt.text] for elt in x])\n",
    "print(philo_df.spacy_sentence.values)\n",
    "print(word2vec_model.wv.key_to_index)\n",
    "# word2vec_model = model.wv.get_vecattr(\"rock\", \"count\")  # 👍\n",
    "# word2vec_model = len(model.wv)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_v3(sentence, series):\n",
    "    vec = [model[str(tok)] for tok in nlp(sentence)]\n",
    "    print('computing similarity')\n",
    "    mat = cosine_similarity(vec, philo_df['spacy_vec'].values)\n",
    "    best_sim_each_token = np.argmax(mat, axis=1)\n",
    "    index = np.argsort(best_sim_each_token)[::-1] #take the five highest norm \n",
    "    print('norms, indices', best_sim_each_token, index)\n",
    "    null_index = best_sim_each_token != 0\n",
    "    null_index = null_index[index]\n",
    "    index = index[null_index==True]\n",
    "    best_index = best_sim_each_token[index][:3]\n",
    "    print('best_index', best_index)\n",
    "    print(philo_df[['sentence', 'author']].iloc[best_index])\n",
    "    return best_index\n",
    "\n",
    "mat = get_recommendations_v3('I can\\'t wait seeing you again', philo_df['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 4 Doc2Vec\n",
    "# import\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(philo_df['spacy_sentence'].values)]\n",
    "\n",
    "# Training Doc2Vec\n",
    "## Train doc2vec model\n",
    "model = Doc2Vec(tagged_data, vector_size = 20, window = 2, min_count = 1, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tagged_data[0])\n",
    "print(model.docvecs)\n",
    "\n",
    "def get_recommendations_v4(sentence, series):\n",
    "    print(sentence.split())\n",
    "    vec = model.infer_vector(sentence.split())\n",
    "    print('computing similarity')\n",
    "    results = model.docvecs.most_similar(positive = [vec])\n",
    "    best_idx, score = list(zip(*results))\n",
    "    print(list(best_idx))\n",
    "    print(philo_df[['sentence', 'author']].iloc[list(best_idx[:3])])\n",
    "    \n",
    "get_recommendations_v4('what is virtue?', philo_df['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 5\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_df['bert_vec'] = philo_df['spacy_sentence'].apply(lambda x: sbert_model.encode(x.text))\n",
    "\n",
    "def get_recommendations_v4(sentence, series):\n",
    "    vec = model.encode([sentence])[0]\n",
    "    print('computing similarity')\n",
    "    mat = cosine_similarity(vec, philo_df['bert_vec'].values)\n",
    "    best_sim_each_token = np.argmax(mat, axis=1)\n",
    "    index = np.argsort(best_sim_each_token)[::-1] #take the five highest norm \n",
    "    print('norms, indices', best_sim_each_token, index)\n",
    "    null_index = best_sim_each_token != 0\n",
    "    null_index = null_index[index]\n",
    "    index = index[null_index==True]\n",
    "    best_index = best_sim_each_token[index][:3]\n",
    "    print('best_index', best_index)\n",
    "    print(philo_df[['sentence', 'author']].iloc[best_index])\n",
    "    return best_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V6 Torch bert transformers\n",
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')    # Download vocabulary from S3 and cache.\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n",
    "# model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased', output_attentions=True)  # Update configuration during loading\n",
    "# assert model.config.output_attentions == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"Who was Jim Henson ?\"\n",
    "text_2 = \"Jim Henson was a puppeteer\"\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 6 #infersen\n",
    "# thank you https://www.analyticsvidhya.com/blog/2020/08/top-4-sentence-embedding-techniques-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir encoder\n",
    "! curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n",
    "  \n",
    "! mkdir GloVe\n",
    "! curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "! unzip GloVe/glove.840B.300d.zip -d GloVe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "import torch\n",
    "\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "model_infersen = InferSent(params_model)\n",
    "model_infersen.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "W2V_PATH = '/content/GloVe/glove.840B.300d.txt'\n",
    "model_infersen.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_infersen.build_vocab(philo_df['spacy_sentence'].values, tokenize=True)\n",
    "infersen_mat = np.array([model.encode([sent])[0] for sent in philo_df['spacy_sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_v4(sentence, series):\n",
    "    vec = model_infersen.encode([sentence])[0]\n",
    "    print('computing similarity')\n",
    "    mat = cosine_similarity(vec, infersen_mat)\n",
    "    best_sim_each_token = np.argmax(mat, axis=1)\n",
    "    index = np.argsort(best_sim_each_token)[::-1] #take the five highest norm \n",
    "    print('norms, indices', best_sim_each_token, index)\n",
    "    null_index = best_sim_each_token != 0\n",
    "    null_index = null_index[index]\n",
    "    index = index[null_index==True]\n",
    "    best_index = best_sim_each_token[index][:3]\n",
    "    print('best_index', best_index)\n",
    "    print(philo_df[['sentence', 'author']].iloc[best_index])\n",
    "    return best_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
